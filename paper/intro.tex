\section{Introduction}\label{sec:intro}

Data aggregation is an integral service for many cloud-based applications.
Such service constantly collects data generated from a large number of sources,
before performing analysis or making decisions.  An example is distributed
messaging service, where a message bus collects messages from many publishers.
Large scale monitoring systems also have similar requirements.  A cluster
management utility would collect performance numbers periodically from all the
machines within a datacenter.  Similar data aggregation occurs in intelligent
sensor networks such as smart power grid and smart home systems.

Formally, given a large number of senders and a single receiver, this paper
addresses the problem of optimizing throughput at the receiver.  This problem
resembles a reversed version of the multicast problem.  In particular, like a
typical tree-based multicast systems, a straightforward solution is to build a
tree structure among the nodes, with the receiver be the root.  Within the tree,
each node forwards messages generated by itself and all other nodes in its
subtree upwards, all the way to the root.

As in tree-based multicast, however, a major limitation with this simple
approach is load imbalance.  Since a node receives and forwards messages from
all the nodes below itself, the load on non-leaf/internal nodes is much higher
than that on leaf nodes of the tree.  In fact, nodes closer to the root receive
higher load, and the maximum throughput of the whole system is bounded by
available bandwidth at the root.

An important difference between the data aggregation problem and multicast is
that in data aggregation, each node generates its own data independently, rather
than forwarding the same data from a unique sender as in multicast.  This
provides the possibility for internal nodes to reduce the load imbalance by
compress the data before forwarding.

This paper presents a system that optimizes data aggregation throughput.  The
key idea in our system is to insert \emph{artificial delays} at internal tree
nodes as messages are being forwarded to the root.  This gives each internal
node the chance to perform \emph{data compaction} using techniques such as
garbage collection to discard messages that are not necessary to be forwarded,
thus reduce the load.  The system provides \emph{prioritization}, so that
urgent messages that cannot afford to be delayed get forwarded immediately.  It
also adaptively allocate \emph{bandwidth quotas} to ensure fairness among data
sources.

The system also utilizes multiple data aggregation trees so that messages
from any node can be forwarded to the root along multiple independent paths.
This scheme provides resiliency to failures, and further reduces load imbalance
across the nodes, as we guarantee that any node is an internal node in at most
one tree.  We present a locality-aware approach to build the trees, as well as
mechanism to reconstruct the trees upon node failure.

We focus our discussion in the context of datacenter network environment, where
machines are organized into interconnected \emph{racks}.  In general, each
machine has the same computing and bandwidth capacity, and bandwidth is limited
by the links that connect individual machines, not among racks.  In addition,
all the machines belong to one administrative domain, and they do not behave
selfishly.  Throughout the paper, we use the term \emph{machine} to refer a
computer in the datacenter that generates and potentially forward messages; we
use the term \emph{node} in the context of overlay data aggregation trees.

This paper is organized as follows.  Section~\ref{sec:design} discusses the
design of our system in detail.  Section~\ref{sec:eval} presents a simulation
study on how the system performs.  We compare our system with related work in
Section~\ref{sec:related}.  Section~\ref{sec:conclusion} concludes and
discusses future directions.

